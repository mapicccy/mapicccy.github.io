<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="IuBNKxWYReEztWCHo-65FPRKh6hr4eEu2OdizQdEg0c">
  <meta name="baidu-site-verification" content="code-X3mIYM4Zeg">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|EB Garamond:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Source Code Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-mac-osx.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mapicccy.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":240,"display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":null,"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Llama 3 模型群 —— Llama 团队，Meta 的 AI 分支 现代人工智能（AI）系统的核心驱动力是基础模型。本文介绍了一组名为 Llama 3 的全新基础模型系列。这是一群原生支持多语言能力、编程、推理以及工具使用的语言模型。我们最大的模型是一个拥有 4050 亿参数和最多可达 12.8 万令牌上下文窗口的密集型 Transformer。本文详细展示了 Llama 3 的大规模实证评">
<meta property="og:type" content="article">
<meta property="og:title" content="The Llama 3 Herd of Models——论文翻译">
<meta property="og:url" content="https://mapicccy.github.io/posts/538b6f3e/index.html">
<meta property="og:site_name" content="mapicccy">
<meta property="og:description" content="Llama 3 模型群 —— Llama 团队，Meta 的 AI 分支 现代人工智能（AI）系统的核心驱动力是基础模型。本文介绍了一组名为 Llama 3 的全新基础模型系列。这是一群原生支持多语言能力、编程、推理以及工具使用的语言模型。我们最大的模型是一个拥有 4050 亿参数和最多可达 12.8 万令牌上下文窗口的密集型 Transformer。本文详细展示了 Llama 3 的大规模实证评">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-07-29T04:54:58.000Z">
<meta property="article:modified_time" content="2024-07-29T05:22:31.388Z">
<meta property="article:author" content="mapicccy">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://mapicccy.github.io/posts/538b6f3e/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>The Llama 3 Herd of Models——论文翻译 | mapicccy</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-JBNFVGV93B"></script>
    <script data-pjax>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-JBNFVGV93B');
      }
    </script>


  <script data-pjax>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?85b9fb02b9e2859d61f68382e3dcb1c1";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="mapicccy" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">mapicccy</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">男人有实力，才有魅力</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://mapicccy.github.io/posts/538b6f3e/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/meizi.jpg">
      <meta itemprop="name" content="mapicccy">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="mapicccy">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          The Llama 3 Herd of Models——论文翻译
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-07-29 04:54:58 / 修改时间：05:22:31" itemprop="dateCreated datePublished" datetime="2024-07-29T04:54:58+00:00">2024-07-29</time>
            </span>

          
            <span class="post-meta-item" title="阅读数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.7k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>11 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Llama 3 模型群 —— Llama 团队，Meta 的 AI 分支</p>
<p>现代人工智能（AI）系统的核心驱动力是基础模型。本文介绍了一组名为 Llama 3 的全新基础模型系列。这是一群原生支持多语言能力、编程、推理以及工具使用的语言模型。我们最大的模型是一个拥有 4050 亿参数和最多可达 12.8 万令牌上下文窗口的密集型 Transformer。本文详细展示了 Llama 3 的大规模实证评估。我们发现，Llama 3 在众多任务上提供了可与顶尖语言模型如 GPT-4 相媲美的质量表现。我们公开发布了 Llama 3，包括预训练和后训练版本的 4050 亿参数语言模型，以及我们的 Llama Guard 3 模型，用于输入和输出的安全保障。</p>
<p>此外，本文还展示了我们通过组合方法将图像、视频和语音能力融入 Llama 3 的实验结果。我们观察到，这种方法在图像、视频和语音识别任务上与最先进水平竞争表现优异。然而，这些融合了多媒体能力的模型目前尚未广泛发布，因为它们仍在开发阶段。</p>
<h3 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h3><p>基础模型是指那些通用的语言、视觉、语音或其他模态的模型，旨在支撑广泛的人工智能任务。它们构成了许多现代AI系统的基石。</p>
<p>现代基础模型的发展历经两大核心阶段：(1) 预训练阶段，模型通过大规模数据集进行训练，采用诸如下一个词预测或图片描述等直接任务；(2) 后训练阶段，模型被微调以遵循指令、与人类偏好对齐及提升特定能力，例如编程和推理。</p>
<p>本文介绍了一组新的语言基础模型——Llama 3系列。Llama 3模型群原生支持多语言、编程、推理及工具运用能力。其中最大的模型是一个密集型Transformer架构，拥有4050亿参数，能在长达12.8万个令牌的上下文窗口中处理信息。模型群的每个成员在表1中列出。本文所展示的所有成果均基于Llama 3.1模型，为简洁起见，我们将统一简称其为Llama 3。</p>
<p>我们认为，高质量基础模型的开发有三个关键要素：数据、规模以及复杂度管理。在开发过程中，我们致力于针对这三个要素进行优化：</p>
<ul>
<li><p><strong>数据</strong>：相较于Llama的早期版本（Touvron等人，2023a,b），我们在预训练和后训练中使用的数据量和质量都有所提升。这些改进包括开发更加细致的预处理和精选管道以优化预训练数据，以及建立更严格的品质保证和过滤方法来处理后训练数据。Llama 3的预训练基于约1.5万亿个多语言令牌的数据集，相比之下，Llama 2使用的数据集为1.8万亿令牌。</p>
</li>
<li><p><strong>规模</strong>: 我们在远超以往Llama模型的规模上进行了训练：我们的旗舰语言模型预训练消耗了大约3.8×10^25次浮点运算（FLOPs），几乎是Llama 2最大版本的近50倍。具体而言，我们对一个拥有4050亿可训练参数的旗舰模型进行了预训练，使用了1.56万亿文本令牌的数据集。正如基础模型的规模法则所预期的那样，我们的旗舰模型在相同的训练流程下超越了规模较小的模型。尽管规模法则表明，对于我们的训练预算，旗舰模型大约处于计算最优的规模，但我们对小型模型的训练时间也远超计算最优时长。由此产生的模型在相同的推理预算下，表现优于计算最优模型。我们还利用旗舰模型在后训练阶段进一步提升了这些小型模型的质量。</p>
</li>
<li><p><strong>管理复杂性</strong>: 我们在设计选择上力求最大化模型开发过程的可扩展性。例如，我们选择了标准的密集型Transformer模型架构（Vaswani等人，2017年），仅做轻微调整，而不是混合专家模型（MoE，Shazeer等人，2017年），以此来最大限度地提高训练稳定性。同样地，我们采用了相对简单的后训练流程，基于监督微调（SFT）、拒绝采样（RS）和直接偏好优化（DPO，Rafailov等人，2023年），而非采用更复杂的强化学习算法（如Ouyang等人，2022年；Schulman等人，2017年），后者往往稳定性较差且难以规模化。</p>
</li>
</ul>
<p>我们的工作成果是Llama 3：一组包含三个多语言模型的“羊驼群”，分别具有80亿、700亿和4050亿个参数。我们对Llama 3在涵盖广泛语言理解任务的关键基准数据集上的性能进行了评估。此外，我们还进行了深入的人类评估，将Llama 3与竞争对手的模型进行比较。旗舰Llama 3模型在关键基准上的性能概览见表2。实验评估表明，我们的旗舰模型在多种任务上与诸如GPT-4（OpenAI，2023a）等领先语言模型的表现相当，并接近达到当前技术前沿。我们的小型模型也是同类最佳，优于具有相似参数数量的替代模型（Bai等人，2023；Jiang等人，2023）。Llama 3相比其前身在有用性和无害性之间取得了更好的平衡（Touvron等人，2023b）。我们将在第5.4节详细介绍Llama 3的安全性分析。</p>
<p>我们正根据更新版的Llama 3社区许可协议公开发布所有三个Llama 3模型；详情请见<a target="_blank" rel="noopener" href="https://llama.meta.com.这包括我们4050亿参数语言模型的预训练和后训练版本,以及输入和输出安全性的llama/">https://llama.meta.com。这包括我们4050亿参数语言模型的预训练和后训练版本，以及输入和输出安全性的Llama</a> Guard模型新版本（Inan等人，2023）。我们希望通过旗舰模型的开放发布激发研究界的创新浪潮，并加速负责任地迈向人工智能（AGI）总体发展的道路。</p>
<p>作为Llama 3开发过程的一部分，我们还开发了模型的多模态扩展，使模型具备图像识别、视频识别和语音理解的能力。这些多模态模型仍在积极开发中，尚未准备发布。除了语言建模的结果外，本文还展示了我们使用这些多模态模型的初步实验结果。</p>
<h3 id="2-总体概述"><a href="#2-总体概述" class="headerlink" title="2 总体概述"></a>2 总体概述</h3><p>Llama 3的模型架构如图1所示。我们Llama 3语言模型的开发包含两个主要阶段：</p>
<h4 id="语言模型预训练"><a href="#语言模型预训练" class="headerlink" title="语言模型预训练"></a>语言模型预训练</h4><p>我们首先将大型多语言文本语料库转换为离散的令牌，并在此基础上预训练一个大型语言模型（LLM），以执行下一个令牌的预测任务。在语言模型预训练阶段，模型学习语言结构，并从其“阅读”的文本中获取大量关于世界的知识。为了有效实现这一目标，预训练是在大规模数据上进行的：我们使用8K令牌的上下文窗口，在15.6万亿个令牌的数据集上预训练一个拥有4050亿参数的模型。这一标准预训练阶段之后是持续预训练阶段，将支持的上下文窗口扩大到128K令牌。详情请参阅第3节。</p>
<h4 id="语言模型后训练"><a href="#语言模型后训练" class="headerlink" title="语言模型后训练"></a>语言模型后训练</h4><p>预训练后的语言模型虽然对语言有了丰富的理解，但还不能遵循指令或像我们期望的助手那样行为。我们通过几轮人类反馈对其校准，每轮涉及在指令调优数据上的监督微调（SFT）和直接偏好优化（DPO，Rafailov等人，2024）。在这一后训练阶段，我们还整合了新能力，比如工具使用，并在编码、推理等领域观察到了显著的进步。详情请见第4节。最后，安全缓解措施也在后训练阶段被整合进模型中，具体细节在第5.4节描述。</p>
<p>最终产生的模型具备一系列丰富的能力。它们能够至少用八种语言回答问题、编写高质量的代码、解决复杂的推理问题，并能开箱即用或以零样本方式使用工具。</p>
<p>我们还进行了实验，通过一种组合方法向Llama 3添加了图像、视频和语音处理能力。我们研究的方法包括图28中所示的三个额外阶段：</p>
<h4 id="多模态编码器预训练"><a href="#多模态编码器预训练" class="headerlink" title="多模态编码器预训练"></a>多模态编码器预训练</h4><p>我们分别为图像和语音训练独立的编码器。我们的图像编码器在大量的图像-文本对上进行训练，这教会模型视觉内容与其自然语言描述之间的关系。语音编码器则采用自监督方法进行训练，该方法会遮蔽语音输入的部分内容，并尝试通过离散令牌表示来重建被遮蔽的部分，从而使模型学习到语音信号的结构。图像编码器的详细信息请参见第7节，语音编码器的详细信息请参见第8节。</p>
<h4 id="视觉适配器训练"><a href="#视觉适配器训练" class="headerlink" title="视觉适配器训练"></a>视觉适配器训练</h4><p>我们训练了一个适配器，将预训练的图像编码器集成到预训练的语言模型中。该适配器包含一系列交叉注意力层，用于将图像编码器的表示馈入语言模型。适配器在文本-图像对上进行训练，这使得图像表示与语言表示对齐。在适配器训练期间，我们也会更新图像编码器的参数，但有意不更新语言模型的参数。我们还在图像适配器的基础上，使用配对的视频-文本数据训练了一个视频适配器，使模型能够在帧间聚合信息。更多细节请参阅第7节。</p>
<h4 id="语音适配器训练"><a href="#语音适配器训练" class="headerlink" title="语音适配器训练"></a>语音适配器训练</h4><p>最后，我们通过一个适配器将语音编码器集成到模型中，该适配器将语音编码转换为可以直接输入到微调过的语言模型中的令牌表示。适配器和编码器的参数在监督微调阶段联合更新，以实现高质量的语音理解能力。在语音适配器训练期间，我们不对语言模型进行更改。我们还集成了一个文本转语音系统。详细信息请参见第8节。</p>
<p>我们的多模态实验产生了能够识别图像和视频内容，并通过语音接口支持交互的模型。这些模型仍处于开发阶段，尚未准备好发布。</p>
<h3 id="3-预训练"><a href="#3-预训练" class="headerlink" title="3 预训练"></a>3 预训练</h3><p>语言模型预训练包括以下步骤：(1) 大规模训练语料库的策划与过滤，(2) 模型架构的开发及确定模型大小的相应规模法则，(3) 大规模高效预训练技术的开发，以及(4) 预训练方案的制定。下面我们将逐一介绍这些组成部分。</p>
<h4 id="3-1-预训练数据"><a href="#3-1-预训练数据" class="headerlink" title="3.1 预训练数据"></a>3.1 预训练数据</h4><p>我们从包含截至2023年底知识的多种数据源创建语言模型预训练数据集。对每个数据源应用多种去重方法和数据清洗机制，以获得高质量的令牌。我们移除含有大量个人可识别信息(PII)的领域，以及已知含有成人内容的领域。</p>
<h4 id="3-1-1-网络数据策划"><a href="#3-1-1-网络数据策划" class="headerlink" title="3.1.1 网络数据策划"></a>3.1.1 网络数据策划</h4><p>我们使用的大部分数据来源于网络，以下是我们的数据清洗流程。</p>
<h5 id="PII和安全过滤"><a href="#PII和安全过滤" class="headerlink" title="PII和安全过滤"></a>PII和安全过滤</h5><p>除其他缓解措施外，我们实施了旨在移除可能含有不安全内容或大量PII的网站数据的过滤器，移除按照Meta安全标准被评为有害的域名，以及已知含有成人内容的域名。</p>
<h5 id="文本提取与清洗"><a href="#文本提取与清洗" class="headerlink" title="文本提取与清洗"></a>文本提取与清洗</h5><p>我们处理非截断网页文档的原始HTML内容，以提取高质量且多样化的文本。为此，我们构建了一个自定义解析器，用于提取HTML内容，并优化去除模板内容的精确度和内容召回率。我们通过人工评估来验证解析器的质量，将其与优化文章类内容的第三方HTML解析器进行对比，结果表现良好。我们仔细处理含有数学和代码内容的HTML页面，以保留这类内容的结构。我们保留图像alt属性文本，因为在数学内容常以预渲染图像形式出现时，数学内容也会在alt属性中提供。我们实验性地评估了不同的清洗配置，发现相比于纯文本，Markdown格式对主要在网页数据上训练的模型性能不利，因此我们移除了所有Markdown标记。</p>
<h5 id="去重"><a href="#去重" class="headerlink" title="去重"></a>去重</h5><p>我们在URL、文档和行级别上应用了几轮去重：</p>
<ul>
<li>URL级去重：在整个数据集中执行URL级别的去重，为每个URL对应的页面保留最新版本。</li>
<li>文档级去重：在整个数据集上执行全局MinHash（Broder, 1997）去重，移除近似重复的文档。</li>
<li>行级去重：执行类似于ccNet（Wenzek等人，2019）的激进行列级去重。移除在每个3000万文档桶中出现超过6次的行。尽管手动定性分析显示，行级去重不仅去除了来自各网站的剩余模板内容（如导航菜单、Cookie警告），也可能移除了频繁出现的高质量文本，但我们的实证评估显示了显著的性能提升。</li>
</ul>
<h5 id="启发式过滤"><a href="#启发式过滤" class="headerlink" title="启发式过滤"></a>启发式过滤</h5><p>我们开发启发式方法来删除更多低质量文档、异常值和重复内容过多的文档。一些启发式例子包括：</p>
<ul>
<li>我们采用重复n-gram覆盖率比例（Rae等人，2021）来删除包含重复内容如日志或错误信息的行。这些行可能非常长且独特，因此无法通过行去重过滤。</li>
<li>我们使用“脏词”计数（Raffel等人，2020）来过滤不受域名屏蔽列表覆盖的成人网站。</li>
<li>我们使用令牌分布的Kullback-Leibler散度来过滤与训练语料库分布相比含有过多异常令牌的文档。</li>
</ul>
<h5 id="基于模型的质量过滤"><a href="#基于模型的质量过滤" class="headerlink" title="基于模型的质量过滤"></a>基于模型的质量过滤</h5><p>我们进一步尝试应用多种基于模型的质量分类器来筛选高质量的文本片段。这包括使用快速分类器，如fasttext（Joulin等人，2017年），该分类器被训练以识别给定文本是否会被维基百科引用（Touvron等人，2023a），以及计算密集型的Roberta-based分类器（Liu等人，2019a），这些分类器在Llama 2的预测数据上进行训练。为了基于Llama 2训练一个质量分类器，我们创建了一个经过清理的网页文档训练集，并描述了质量要求，然后指导Llama 2的聊天模型判断文档是否满足这些要求。出于效率考虑，我们使用DistilRoberta（Sanh等人，2019年）为每个文档生成质量分数。我们通过实验评估了不同质量过滤配置的有效性。</p>
<h5 id="代码与推理数据处理"><a href="#代码与推理数据处理" class="headerlink" title="代码与推理数据处理"></a>代码与推理数据处理</h5><p>类似于DeepSeek-AI等（2024年）的工作，我们构建了针对特定领域的管道，用于提取包含代码和数学相关内容的网页。具体而言，无论是代码还是推理分类器，都是基于DistilledRoberta模型，该模型在由Llama 2标注的网络数据上进行训练。与上述通用质量分类器不同，我们进行了提示调整，以便针对性地搜索包含数学推导、STEM领域中的推理以及自然语言中穿插的代码的网页。鉴于代码和数学的令牌分布与自然语言有显著差异，这些管道实现了领域特定的HTML抽取、定制的文本特征和过滤启发式规则。</p>
<h5 id="多语言数据处理"><a href="#多语言数据处理" class="headerlink" title="多语言数据处理"></a>多语言数据处理</h5><p>与上述针对英语的数据处理流程相仿，我们也实施了过滤机制，以移除可能包含个人身份信息（PII）或不安全内容的网站数据。我们的多语言文本处理管道具备以下独特特性：</p>
<p>• 利用基于fasttext的语言识别模型，将文档归类到176种语言中。<br>• 针对每种语言的数据，分别在文档级别和行级别执行去重复操作。<br>• 应用针对各语言的特定启发式规则及基于模型的过滤器，以排除低质量文档。</p>
<p>此外，我们采用基于多语言Llama 2的分类器对多语言文档进行质量排序，确保优先考虑高质量内容。通过实验确定预训练中使用的多语言令牌数量，以平衡模型在英语和多语言基准测试上的性能表现。</p>
<h4 id="3-1-2-数据组合的确定"><a href="#3-1-2-数据组合的确定" class="headerlink" title="3.1.2 数据组合的确定"></a>3.1.2 数据组合的确定</h4><p>为了获得高质量的语言模型，仔细决定预训练数据混合中不同数据来源的比例至关重要。我们确定此数据混合的主要工具是知识分类和规模法则实验。</p>
<p><strong>知识分类。</strong> 我们开发了一种分类器，用于分类网络数据中所含信息的类型，以便更有效地确定数据组合。我们利用该分类器对网络上过度代表的数据类别进行下采样，例如艺术与娱乐类内容。</p>
<p><strong>数据混合的规模法则。</strong> 为确定最佳数据组合，我们执行规模法则实验，即在不同的数据组合上训练多个小型模型，并以此预测大型模型在该组合上的性能（参见第3.2.1节）。我们为不同的数据组合多次重复这一过程，以选择新的数据组合候选。随后，在这个候选数据组合上训练一个更大的模型，并评估其在几个关键基准测试上的表现。</p>
<p><strong>数据组合概述。</strong> 最终的数据组合大约包含50%的一般知识令牌，25%的数学与推理令牌，17%的代码令牌，以及8%的多语言令牌。</p>
<h4 id="3-1-3-数据退火"><a href="#3-1-3-数据退火" class="headerlink" title="3.1.3 数据退火"></a>3.1.3 数据退火</h4><p>实验上，我们发现对少量高质量的代码和数学数据进行退火（参见第3.4.3节）可以提升预训练模型在关键基准上的性能。类似于Li等人（2024b），我们在特定领域内对高质量数据进行上采样的数据混合上执行退火。我们的退火数据中不包含任何来自常用基准测试的训练集。这使我们能够评估Llama 3真正的少量样本学习能力和跨领域的泛化能力。</p>
<p>效仿OpenAI（2023a），我们在GSM8k（Cobbe等人，2021）和MATH（Hendrycks等人，2021b）训练集上进行退火，并评估退火的效果。我们发现，退火使预训练的Llama 3 8B模型在GSM8k和MATH验证集上的性能分别提高了24.0%和6.4%。然而，对于405B模型，改进微乎其微，表明我们的旗舰模型拥有强大的上下文内学习和推理能力，不需要特定领域的训练样本即可获得强劲的性能。</p>
<p><strong>利用退火评估数据质量。</strong> 类似于Blakeney等人（2024），我们发现退火使我们能够评判小规模领域特定数据集的价值。我们通过线性地将一个已训练50%的Llama 3 8B模型的学习率退火至0，处理400亿个令牌，以此来衡量这类数据集的价值。在这些实验中，新数据集被赋予30%的权重，剩余70%的权重分配给默认数据混合。相比为每个小数据集执行规模法则实验，使用退火评估新数据源更为高效。</p>
<h3 id="3-2-模型架构"><a href="#3-2-模型架构" class="headerlink" title="3.2 模型架构"></a>3.2 模型架构</h3><p>Llama 3采用了标准的稠密Transformer架构（Vaswani等人，2017年）。就模型架构而言，它与Llama及Llama 2（Touvron等人，2023a，b）并无显著偏离；我们的性能提升主要得益于数据质量和多样性的改进，以及训练规模的扩大。</p>
<p>相较于Llama 3，我们做出了一些较小的修改：</p>
<p>• 我们采用了分组查询注意力（Grouped Query Attention，简称GQA；Ainslie等人，2023年），并设置了8个键值头，以提高推理速度并减少解码期间键值缓存的大小。<br>• 我们使用了一种注意力掩码，防止序列中不同文档之间的自注意力。我们发现在标准预训练过程中，这一改动的影响有限，但在针对非常长序列的持续预训练中，我们发现它非常重要。</p>

    </div>

    
    
    <script src="//sdk.jinrishici.com/v2/browser/jinrishici.js"></script>
<script>
  jinrishici.load((result) => {
    let jrsc = document.getElementById('jrsc');
    const data = result.data;
    let author = data.origin.author;
    let title = '《' + data.origin.title + '》';
    let content = data.content.substr(0, data.content.length - 1);
    let dynasty = data.origin.dynasty.substr(0, data.origin.dynasty.length - 1);
    jrsc.innerText = content + ' @ ' + dynasty + '·' + author + title;
  });
</script>
<div style="text-align: center"><span id="jrsc" >正在加载今日诗词....</span></div>


        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>mapicccy
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://mapicccy.github.io/posts/538b6f3e/" title="The Llama 3 Herd of Models——论文翻译">https://mapicccy.github.io/posts/538b6f3e/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-mapicccy/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-MAPICCCY</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/posts/db9f248e/" rel="prev" title="ARM64使用kernel 6.6.7启动日志">
      <i class="fa fa-chevron-left"></i> ARM64使用kernel 6.6.7启动日志
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%BC%95%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">1 引言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%80%BB%E4%BD%93%E6%A6%82%E8%BF%B0"><span class="nav-number">2.</span> <span class="nav-text">2 总体概述</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="nav-number">2.1.</span> <span class="nav-text">语言模型预训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%90%8E%E8%AE%AD%E7%BB%83"><span class="nav-number">2.2.</span> <span class="nav-text">语言模型后训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E7%BC%96%E7%A0%81%E5%99%A8%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="nav-number">2.3.</span> <span class="nav-text">多模态编码器预训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%A7%86%E8%A7%89%E9%80%82%E9%85%8D%E5%99%A8%E8%AE%AD%E7%BB%83"><span class="nav-number">2.4.</span> <span class="nav-text">视觉适配器训练</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AF%AD%E9%9F%B3%E9%80%82%E9%85%8D%E5%99%A8%E8%AE%AD%E7%BB%83"><span class="nav-number">2.5.</span> <span class="nav-text">语音适配器训练</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E9%A2%84%E8%AE%AD%E7%BB%83"><span class="nav-number">3.</span> <span class="nav-text">3 预训练</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-%E9%A2%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="nav-number">3.1.</span> <span class="nav-text">3.1 预训练数据</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-%E7%BD%91%E7%BB%9C%E6%95%B0%E6%8D%AE%E7%AD%96%E5%88%92"><span class="nav-number">3.2.</span> <span class="nav-text">3.1.1 网络数据策划</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#PII%E5%92%8C%E5%AE%89%E5%85%A8%E8%BF%87%E6%BB%A4"><span class="nav-number">3.2.1.</span> <span class="nav-text">PII和安全过滤</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E6%8F%90%E5%8F%96%E4%B8%8E%E6%B8%85%E6%B4%97"><span class="nav-number">3.2.2.</span> <span class="nav-text">文本提取与清洗</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%8E%BB%E9%87%8D"><span class="nav-number">3.2.3.</span> <span class="nav-text">去重</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%90%AF%E5%8F%91%E5%BC%8F%E8%BF%87%E6%BB%A4"><span class="nav-number">3.2.4.</span> <span class="nav-text">启发式过滤</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%B4%A8%E9%87%8F%E8%BF%87%E6%BB%A4"><span class="nav-number">3.2.5.</span> <span class="nav-text">基于模型的质量过滤</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E4%B8%8E%E6%8E%A8%E7%90%86%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">3.2.6.</span> <span class="nav-text">代码与推理数据处理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A4%9A%E8%AF%AD%E8%A8%80%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="nav-number">3.2.7.</span> <span class="nav-text">多语言数据处理</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-%E6%95%B0%E6%8D%AE%E7%BB%84%E5%90%88%E7%9A%84%E7%A1%AE%E5%AE%9A"><span class="nav-number">3.3.</span> <span class="nav-text">3.1.2 数据组合的确定</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-3-%E6%95%B0%E6%8D%AE%E9%80%80%E7%81%AB"><span class="nav-number">3.4.</span> <span class="nav-text">3.1.3 数据退火</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="nav-number">4.</span> <span class="nav-text">3.2 模型架构</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="mapicccy"
      src="/images/meizi.jpg">
  <p class="site-author-name" itemprop="name">mapicccy</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/mapicccy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;mapicccy" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:guanjun@linux.alibaba.com" title="E-Mail → mailto:guanjun@linux.alibaba.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">mapicccy</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">87k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">2:25</span>
</div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>


        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '8ec0558d573a795f94f7',
      clientSecret: '796322758985b8b2732442b8ce2dfef6a96465bc',
      repo        : 'mapicccy.github.io',
      owner       : 'mapicccy',
      admin       : ['mapicccy'],
      id          : 'b76f4c69d7f9e3efbc67de506a7d29bc',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>

<script type="text/javascript" src="/js/src/love.js"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"left","width":200,"height":400},"mobile":{"show":true}});</script></body>
</html>
